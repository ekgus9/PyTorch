{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15_sequence.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPM4+C/Js0Yk6kiwtiiOG8y"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- Sequence Labeling\n",
        "\n",
        "  RNN 다 대 다 & bidirectional RNN -> 개체명 인식기, 품사 태거\n",
        "\n",
        "  sequence labeling : 입력 시퀀스에 대해 레이블 시퀀스를 각각 부여\n",
        "\n",
        "- bidirectional RNN을 이용한 품사 태깅\n",
        "\n"
      ],
      "metadata": {
        "id": "giAOxw6pZIit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "import time\n",
        "import random\n",
        "device = 'cpu'\n",
        "\n",
        "text = data.Field(lower = True)\n",
        "ud = data.Field(unk_token = None)\n",
        "ptb = data.Field(unk_token = None)\n",
        "\n",
        "fields = ((\"text\", text), (\"udtags\", ud), (\"ptbtags\", ptb))\n",
        "\n",
        "train, valid, test = datasets.UDPOS.splits(fields)"
      ],
      "metadata": {
        "id": "rN9AQ4eMacH5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary\n",
        "min_freq = 5\n",
        "\n",
        "text.build_vocab(train,min_freq = min_freq, vectors = 'glove.6B.100d') # GloVe\n",
        "ud.build_vocab(train)\n",
        "ptb.build_vocab(train)\n",
        "\n",
        "ud.vocab.freqs.most_common(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoAltPC1g4a0",
        "outputId": "8e538fcd-8667-41e9-aff6-481d09c8e230"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:17<00:00, 22225.98it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NOUN', 34781),\n",
              " ('PUNCT', 23679),\n",
              " ('VERB', 23081),\n",
              " ('PRON', 18577),\n",
              " ('ADP', 17638),\n",
              " ('DET', 16285),\n",
              " ('PROPN', 12946),\n",
              " ('ADJ', 12477),\n",
              " ('AUX', 12343),\n",
              " ('ADV', 10548),\n",
              " ('CCONJ', 6707),\n",
              " ('PART', 5567),\n",
              " ('NUM', 3999),\n",
              " ('SCONJ', 3843),\n",
              " ('X', 847),\n",
              " ('INTJ', 688),\n",
              " ('SYM', 599)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader\n",
        "batchsize = 64\n",
        "\n",
        "train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train, valid, test),\n",
        "    batch_size = batchsize,\n",
        "    device = device\n",
        ")"
      ],
      "metadata": {
        "id": "AUBvcWySiEvc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNPOSTagger(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional)\n",
        "    self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text):\n",
        "    embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "    outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "    predictions = self.fc(self.dropout(outputs))\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "WkSeNA6ci0HA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNPOSTagger(len(text.vocab), 100, 128, len(ud.vocab), 2, True, 0.25).to(device)"
      ],
      "metadata": {
        "id": "AarUlOTUnlbj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = text.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "unk = text.vocab.stoi[text.unk_token] # 0\n",
        "pad = text.vocab.stoi[text.pad_token] # 1\n",
        "\n",
        "model.embedding.weight.data[unk] = torch.zeros(100)\n",
        "model.embedding.weight.data[pad] = torch.zeros(100)"
      ],
      "metadata": {
        "id": "-eMFv_45oIft"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TAG_PAD_IDX = ud.vocab.stoi[ud.pad_token]\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX).to(device)"
      ],
      "metadata": {
        "id": "3WBp1mZ6pzYU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_accuracy(preds,y,tag_pad_idx):\n",
        "  # 미니 배치 정확도 출력\n",
        "  max_preds = preds.argmax(dim = 1, keepdim = True)\n",
        "  non_pad_elements = (y != tag_pad_idx).nonzero()\n",
        "  correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
        "  return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]])"
      ],
      "metadata": {
        "id": "2hAlE0hbqqWX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,iter, optim, criterion,tag_pad_idx):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch in iter:\n",
        "    text = batch.text\n",
        "    tags = batch.udtags\n",
        "\n",
        "    optim.zero_grad()\n",
        "    predictions = model(text)\n",
        "\n",
        "    predictions = predictions.view(-1,predictions.shape[-1])\n",
        "    tags = tags.view(-1)\n",
        "    loss = criterion(predictions,tags)\n",
        "    acc = categorical_accuracy(predictions,tags,tag_pad_idx)\n",
        "\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iter), epoch_acc / len(iter)"
      ],
      "metadata": {
        "id": "HsvmH9ParfWm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "\n",
        "            text = batch.text\n",
        "            tags = batch.udtags\n",
        "\n",
        "            predictions = model(text)\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "w1DECNg8u-GQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(10):\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iter, optimizer, criterion, TAG_PAD_IDX)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iter, criterion, TAG_PAD_IDX)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LJNqhJAvHcy",
        "outputId": "0356beee-84cb-4c5d-f253-315573d62fc7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 1.090 | Train Acc: 66.17%\n",
            "\t Val. Loss: 0.660 |  Val. Acc: 79.91%\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.391 | Train Acc: 87.67%\n",
            "\t Val. Loss: 0.528 |  Val. Acc: 83.50%\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.307 | Train Acc: 90.05%\n",
            "\t Val. Loss: 0.486 |  Val. Acc: 84.46%\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.267 | Train Acc: 91.31%\n",
            "\t Val. Loss: 0.459 |  Val. Acc: 85.07%\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.239 | Train Acc: 92.14%\n",
            "\t Val. Loss: 0.456 |  Val. Acc: 85.14%\n",
            "Epoch: 06\n",
            "\tTrain Loss: 0.220 | Train Acc: 92.78%\n",
            "\t Val. Loss: 0.428 |  Val. Acc: 85.58%\n",
            "Epoch: 07\n",
            "\tTrain Loss: 0.205 | Train Acc: 93.22%\n",
            "\t Val. Loss: 0.412 |  Val. Acc: 86.29%\n",
            "Epoch: 08\n",
            "\tTrain Loss: 0.191 | Train Acc: 93.69%\n",
            "\t Val. Loss: 0.419 |  Val. Acc: 86.10%\n",
            "Epoch: 09\n",
            "\tTrain Loss: 0.179 | Train Acc: 94.07%\n",
            "\t Val. Loss: 0.409 |  Val. Acc: 87.02%\n",
            "Epoch: 10\n",
            "\tTrain Loss: 0.168 | Train Acc: 94.43%\n",
            "\t Val. Loss: 0.400 |  Val. Acc: 88.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model,test_iter, criterion,TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48AAte3hvZ9d",
        "outputId": "2ee09965-cac2-4893-d0e8-4bfaaa17e748"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.401 |  Test Acc: 87.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sequence to Sequence, seq2seq\n",
        "\n",
        "  인코더와 디코더로 구성, 번역에서 주로 사용\n",
        "\n",
        "  인코더 안 lstm or gru 셀들로 구성\n",
        "\n",
        "  인코더 rnn 셀은 인코더 rnn 셀의 마지막 시점 은닉 상태를 디코더로 넘겨주는데 이를 **컨텍스트 벡터**라 한다.\n",
        "\n",
        "  - 테스트 단계\n",
        "\n",
        "    디코더는 <sos>가 입력되면 다음 등장 확률이 높은 단어 예측 -> <eos>가 다음 단어로 예측 될 때까지 예측한 단어를 다음시점 rnn 셀로 넣는 것을 반복\n",
        "\n",
        "  - 훈련 단계와 교사 강요\n",
        "\n",
        "    디코더에게 인코더가 보낸 컨벡스트 벡터와 실제 정답을 알려주며 훈련 : 교사 강요 teacher forcing\n",
        "\n",
        "  - embedding layer\n",
        "\n",
        "  - rnn 셀\n",
        "\n",
        "  - 디코더\n",
        "\n",
        "    인코더의 마지막 rnn 셀의 은닉 상태인 컨텍스트 벡터를 첫번째 은닉상태 값으로 사용. 다음에 등장할 단어 예측. 모든 단어로부터 softmax function을 이용하여 하나의 단어를 골라야 함.\n",
        " "
      ],
      "metadata": {
        "id": "kbv7TluRcQSm"
      }
    }
  ]
}