{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_WordEmbedding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+P2pff7MlL+Mi345+XHBj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- Word2Vec\n",
        "\n",
        "  distributed representation으로 단어의 유사도 계산 가능\n",
        "\n",
        "  CBOW & Skip-gram\n",
        "\n",
        "- GloVe\n",
        "\n",
        "  LSA : 각 단어의 빈도수를 카운트 한 행렬이라는 전체적인 통계 정보를 입력으로 받아 차원을 축소하여 잠재된 의미를 끌어내는 방법론 (의미 유추는 불가)\n",
        "\n",
        "  word2vec : 실제값과 예측값에 대한 오차를 손실 함수를 통해 줄여가며 학습하는 예측 기반 방법론 (코퍼스의 전체적인 통계 정보는 반영 불가)\n",
        "\n",
        "  -> GloVe는 두가지를 모두 반영\n",
        "\n",
        "  : 임베딩 된 중심 단어와 주변 단어 벡터의 내적이 전체 코퍼스에서 Co-occurrence Probability이 되도록 만드는 것\n",
        "\n",
        "- nn.Embedding() in PyTorch\n",
        "\n",
        "  단어 -> 단어에 부여된 정수값(not one-hot) -> 임베딩 층 통과 -> 밀집 벡터\n",
        "\n"
      ],
      "metadata": {
        "id": "rzk-Mrf1O7OR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 룩업 테이블 구현\n",
        "\n",
        "train_data = 'you need to know how to code'\n",
        "\n",
        "word_set = set(train_data.split())\n",
        "vocab = {word:i+2 for i,word in enumerate(word_set)}\n",
        "vocab['<unk>'] = 0\n",
        "vocab['<pad>'] = 1\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LsFnWlge5CB",
        "outputId": "817aa4c3-93c8-4283-e565-edb5285c8dd8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<pad>': 1,\n",
              " '<unk>': 0,\n",
              " 'code': 2,\n",
              " 'how': 7,\n",
              " 'know': 3,\n",
              " 'need': 6,\n",
              " 'to': 5,\n",
              " 'you': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "embedding_table = torch.FloatTensor([\n",
        "                               [ 0.0,  0.0,  0.0],\n",
        "                               [ 0.0,  0.0,  0.0],\n",
        "                               [ 0.2,  0.9,  0.3],\n",
        "                               [ 0.1,  0.5,  0.7],\n",
        "                               [ 0.2,  0.1,  0.8],\n",
        "                               [ 0.4,  0.1,  0.1],\n",
        "                               [ 0.1,  0.8,  0.9],\n",
        "                               [ 0.6,  0.1,  0.1]])"
      ],
      "metadata": {
        "id": "AI4lTXy_f0bX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = 'you need to run'.split()\n",
        "idx = []\n",
        "\n",
        "for w in sample:\n",
        "  try:\n",
        "    idx.append(vocab[w])\n",
        "  except KeyError:\n",
        "    idx.append(vocab['<unk>'])\n",
        "\n",
        "idx = torch.LongTensor(idx)\n",
        "\n",
        "lookup = embedding_table[idx,:]\n",
        "lookup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0q6HgYPfpE6",
        "outputId": "04ea2bf2-163a-4cc5-dd5b-cca9e76e36e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2000, 0.1000, 0.8000],\n",
              "        [0.1000, 0.8000, 0.9000],\n",
              "        [0.4000, 0.1000, 0.1000],\n",
              "        [0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Embedding() 사용\n",
        "import torch.nn as nn\n",
        "embedding_layer = nn.Embedding(num_embeddings = len(vocab), # 단어집합 크기\n",
        "                               embedding_dim = 3,\n",
        "                               padding_idx = 1)\n",
        "\n",
        "embedding_layer.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fyScKibgrFh",
        "outputId": "1328e73f-81ef-44c8-b2e2-3513fb06cd96"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.1271,  0.1678,  0.1965],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [-0.4390,  1.5269, -0.7928],\n",
              "        [-0.2572,  0.1868, -0.6623],\n",
              "        [ 1.2374,  0.7994,  1.0443],\n",
              "        [ 0.7624, -0.4105,  1.4969],\n",
              "        [-0.2873,  0.0816, -1.0918],\n",
              "        [ 2.7678,  0.1585,  0.8112]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pretrained Word Embedding\n",
        "\n"
      ],
      "metadata": {
        "id": "hmZsj4h-js1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using IMDB review data for training\n",
        "\n",
        "from torchtext.legacy import data, datasets\n",
        "\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = data.Field(sequential=False, batch_first=True)\n",
        "\n",
        "trainset, testset = datasets.IMDB.splits(TEXT,LABEL)\n",
        "\n",
        "vars(trainset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHdVz6Ykj4Pg",
        "outputId": "004bff19-649b-4f91-f26e-43cbe566ae02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84.1M/84.1M [00:11<00:00, 7.48MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'pos',\n",
              " 'text': ['this',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'best',\n",
              "  'movies',\n",
              "  'out',\n",
              "  'there',\n",
              "  'and',\n",
              "  \"that's\",\n",
              "  'saying',\n",
              "  'a',\n",
              "  'lot',\n",
              "  'being',\n",
              "  'that',\n",
              "  'it',\n",
              "  'was',\n",
              "  'for',\n",
              "  'television.',\n",
              "  'i',\n",
              "  'really',\n",
              "  'wish',\n",
              "  'it',\n",
              "  'was',\n",
              "  'on',\n",
              "  'd.v.d.<br',\n",
              "  '/><br',\n",
              "  '/>helen',\n",
              "  'hunt',\n",
              "  'gave',\n",
              "  'such',\n",
              "  'a',\n",
              "  'raw',\n",
              "  'performance.',\n",
              "  'she',\n",
              "  'played',\n",
              "  'a',\n",
              "  'rookie',\n",
              "  'cop',\n",
              "  'thrown',\n",
              "  'into',\n",
              "  'serial',\n",
              "  'killer',\n",
              "  'case',\n",
              "  'perfectly.',\n",
              "  'when',\n",
              "  'she',\n",
              "  'falls',\n",
              "  'apart',\n",
              "  'because',\n",
              "  'he',\n",
              "  'kills',\n",
              "  'another',\n",
              "  'kid',\n",
              "  'it',\n",
              "  'was',\n",
              "  'amazing.',\n",
              "  'she',\n",
              "  'is',\n",
              "  'so',\n",
              "  'alone,',\n",
              "  'so',\n",
              "  'he',\n",
              "  'gets',\n",
              "  'to',\n",
              "  'her.',\n",
              "  'when',\n",
              "  'she',\n",
              "  'talks',\n",
              "  'about',\n",
              "  'her',\n",
              "  'mother!',\n",
              "  'wow!<br',\n",
              "  '/><br',\n",
              "  '/>steven',\n",
              "  'weber',\n",
              "  'as',\n",
              "  'the',\n",
              "  'serial',\n",
              "  'killer',\n",
              "  'was',\n",
              "  'so',\n",
              "  'shocking!',\n",
              "  'he',\n",
              "  'really',\n",
              "  'brought',\n",
              "  'her',\n",
              "  'into',\n",
              "  'his',\n",
              "  'dark',\n",
              "  'world.',\n",
              "  'it',\n",
              "  'was',\n",
              "  'oscar-worthy.',\n",
              "  'when',\n",
              "  'he',\n",
              "  'talks',\n",
              "  'about',\n",
              "  'killing',\n",
              "  'the',\n",
              "  'kids,',\n",
              "  'scary!',\n",
              "  'when',\n",
              "  'he',\n",
              "  'realizes',\n",
              "  'who',\n",
              "  'she',\n",
              "  'really',\n",
              "  'is!',\n",
              "  'what',\n",
              "  'a',\n",
              "  'scene!!<br',\n",
              "  '/><br',\n",
              "  '/>they',\n",
              "  'really',\n",
              "  \"don't\",\n",
              "  'make',\n",
              "  'them',\n",
              "  'like',\n",
              "  'that',\n",
              "  'anymore.',\n",
              "  'it',\n",
              "  'was',\n",
              "  'a',\n",
              "  'real',\n",
              "  'thriller',\n",
              "  'without',\n",
              "  'being',\n",
              "  'gory.']}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import GloVe\n",
        "\n",
        "TEXT.build_vocab(trainset, vectors=GloVe(name='6B', dim=300), max_size=10000, min_freq=10)\n",
        "LABEL.build_vocab(trainset)\n",
        "\n",
        "embedding_layer = nn.Embedding.from_pretrained(TEXT.vocab.vectors, freeze=False)\n",
        "embedding_layer(torch.LongTensor([10])) # nn.Embedding의 초기 입력값으로 TEXT.vocab.vectors 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJwRBifNknNQ",
        "outputId": "5b2a38c0-7d0c-434d-f36e-a998e14b58f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:42, 5.30MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:47<00:00, 8420.33it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.0437e-01,  1.6431e-01,  4.1794e-02, -1.3708e-01, -2.9779e-01,\n",
              "          3.3440e-01, -6.9955e-02, -6.8036e-02,  1.0604e-01, -2.0337e+00,\n",
              "          1.7977e-01, -7.7403e-02, -1.9518e-01,  1.8324e-01,  3.0017e-02,\n",
              "         -5.4762e-02, -4.5725e-01, -2.4509e-02,  5.7387e-02, -3.4878e-01,\n",
              "          3.9696e-02,  4.4826e-01, -5.8462e-02,  4.1181e-01, -3.5411e-02,\n",
              "         -1.4722e-01,  1.0740e-01, -2.5896e-01, -1.1658e-01,  1.9822e-01,\n",
              "          3.2850e-01,  2.4177e-01, -5.7177e-01, -5.6442e-02, -9.6437e-01,\n",
              "          3.4482e-01,  5.4639e-02,  2.3828e-01, -1.9139e-01,  3.0899e-01,\n",
              "          2.8044e-01, -3.3814e-02, -2.5436e-01,  1.5373e-02,  1.6341e-01,\n",
              "          2.6352e-01,  1.5812e-01,  3.2044e-01, -2.3082e-01,  2.6050e-01,\n",
              "          2.0606e-01, -8.9769e-02, -1.0055e-01,  7.0378e-02, -2.7452e-02,\n",
              "          2.7959e-01, -9.5862e-02,  2.0574e-01,  2.9522e-01, -1.2285e-02,\n",
              "          1.1164e-01, -5.1373e-02,  4.6106e-01,  2.3014e-02, -3.7141e-01,\n",
              "         -2.4166e-01,  3.3773e-02,  3.6827e-02,  1.6918e-01, -1.0802e-01,\n",
              "         -1.0691e-01,  1.0219e-01,  1.0065e-01,  5.5907e-02, -2.7402e-01,\n",
              "         -1.3689e-01,  4.2095e-01, -2.4060e-02, -3.2099e-01,  3.2065e-01,\n",
              "         -1.6776e-01,  1.0170e-01,  7.4999e-02, -1.0486e-01,  3.7114e-01,\n",
              "          3.2972e-01, -3.3043e-01,  3.8343e-01,  2.4555e-01,  2.0386e-01,\n",
              "         -4.1919e-01,  1.1570e-01, -7.8632e-02, -4.3171e-01, -2.3550e-02,\n",
              "         -1.1618e-01, -2.5605e-01,  3.4693e-01,  2.0398e-01, -1.7857e-01,\n",
              "          1.7301e-01,  4.6408e-02, -1.0486e-01,  9.8706e-02, -3.2077e-02,\n",
              "         -3.0462e-01,  1.2826e-01,  6.7985e-02, -2.5993e-01,  3.8041e-01,\n",
              "          4.5252e-02, -9.1834e-02, -4.5206e-01, -1.2498e-01,  1.7515e-01,\n",
              "         -1.3551e-01, -2.0556e-03, -9.3906e-02, -2.8006e-02, -4.6975e-01,\n",
              "          8.4430e-03, -2.4092e-01,  1.6000e-01,  2.2063e-01,  3.6277e-01,\n",
              "         -6.7643e-02,  2.8755e-01,  1.2643e-01,  1.2202e-01,  1.0548e-01,\n",
              "          4.0249e-01,  2.9781e-01,  4.9507e-01, -1.1096e-01, -2.4472e-01,\n",
              "          1.8720e-01,  1.1156e-01,  1.5680e-02,  7.6296e-03,  1.4304e-01,\n",
              "         -2.9299e-01,  1.7912e-01,  1.1604e-02, -5.6776e-02, -5.0224e-01,\n",
              "         -4.7262e-01,  1.5790e-01,  3.1573e-01, -7.7839e-02,  3.5172e-01,\n",
              "          1.6097e-01, -2.2595e-01,  2.4629e-01, -3.8200e-02,  6.4918e-01,\n",
              "          5.9545e-02, -5.0641e-02,  1.9511e-01, -6.8791e-02, -1.5146e-01,\n",
              "          1.2101e-02, -4.5943e-01,  1.4300e-02, -8.7461e-02, -3.2711e-02,\n",
              "          2.4036e-01,  1.7293e-02,  1.1340e-01, -3.4248e-02,  5.0351e-02,\n",
              "          9.3530e-02, -6.4975e-02, -8.5025e-01, -1.3809e-01, -3.4919e-01,\n",
              "         -2.0540e-02, -3.7268e-01,  4.7773e-02,  4.7216e-02,  2.3236e-01,\n",
              "          1.3777e-01,  2.4962e-01,  1.3133e-01,  4.7732e-02,  4.4829e-02,\n",
              "         -1.3243e-01, -1.6702e-01,  2.1045e-01, -4.0940e-02,  3.1555e-01,\n",
              "         -5.1593e-01,  1.0297e-01,  2.9704e-01,  1.6769e-02, -2.1701e-02,\n",
              "          5.7481e-03,  6.0955e-02, -2.2314e-02,  1.6080e-01, -2.1614e-01,\n",
              "          1.0959e+00, -4.0587e-01, -1.4514e-01, -1.3610e-01,  1.1280e-01,\n",
              "          1.7697e-01, -6.5900e-02, -1.3467e-01, -5.1049e-02, -2.8790e-01,\n",
              "         -3.9537e-01,  7.9347e-02,  5.7817e-01, -1.2027e-02, -1.2462e-01,\n",
              "          4.0711e-02,  1.3596e-02,  2.0398e-01,  9.5604e-02,  6.8153e-03,\n",
              "          2.5994e-01, -1.0152e-01, -3.8128e-01,  4.2629e-01,  1.8734e-01,\n",
              "          7.3060e-03,  6.0062e-01,  2.1663e-01,  2.3836e-02,  1.2912e-02,\n",
              "         -3.0333e-01,  3.1381e-01, -2.6096e-02, -3.8907e-01,  5.5081e-02,\n",
              "         -5.0901e-02,  2.5939e-01, -2.6417e-01,  2.0716e-01,  2.2498e-01,\n",
              "          1.9117e-01,  1.2614e-01,  1.4713e-01,  1.0489e-01, -1.1291e+00,\n",
              "         -8.1722e-02,  1.2693e-01,  1.5365e-01, -8.2781e-02, -3.5168e-01,\n",
              "          1.7873e-01, -9.7911e-02, -2.5831e-01,  9.0010e-03,  3.9271e-01,\n",
              "          9.9305e-02,  2.0227e-02,  9.2149e-03,  3.3352e-01, -7.1636e-02,\n",
              "         -5.9093e-02,  9.9506e-02,  3.1135e-01,  3.1324e-01, -1.0208e-01,\n",
              "         -6.0717e-02, -4.3183e-02, -8.3102e-02,  5.3218e-01, -1.6997e-01,\n",
              "          1.1647e-01, -1.0793e-01, -3.3692e-02,  1.6272e-01,  2.0517e-01,\n",
              "          1.1426e-01, -2.0803e+00, -4.4386e-03,  8.7898e-01,  4.7096e-01,\n",
              "         -2.7657e-01, -1.9387e-01, -9.8869e-02, -1.1244e-01, -1.4206e-01,\n",
              "          9.0613e-02, -1.8396e-01,  3.6844e-02, -1.9090e-01,  8.6006e-02,\n",
              "          9.2397e-04, -4.1547e-01, -7.7672e-02,  5.0569e-01,  2.4725e-01,\n",
              "          2.4119e-01, -1.3455e-01, -3.4007e-01, -7.7146e-02, -8.4089e-02]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}